## 데이터

### 데이터 변경에 흔적 남기기

- 데이터 쓰기: 주요 데이터 변경에 대해 로그(audit log)를 남기는 것은 아주 중요함
- 고객 문의가 들어왔을 때 쓰는 시간을 1/10으로 줄여줌
- 가끔 고객은 실수로 (혹은 고의로) 데이터를 변경하거나 삭제하고 문의를 하곤 함
- 고객이 의도한 변경이었는지, 비즈니스 로직의 결함인지 판단하는 데에도 중요한 근거가 됨
- 디버깅할 때 주변 맥락을 재현할 수 있는 정보를 제공해줌

  - audit log에 들어가는 정보
    - 어떤 엔티티에 추가/변경/삭제가 일어났는가
    - 어떤 주체가 행동했는가 (사용자에 의한 변경 외에도 시스템이나 Admin에 의한 변경도 로깅 함)
    - 언제 write가 일어났는가
      - audit log 뿐만 아니라 모든 데이터베이스 테이블에는 생성/수정 timestamp가 들어가도록 구성함
      - 때로 수정이 일어날 때마다 increment 되는 버전 컬럼을 운용할 때도 있음
    - 기타 정보
      - 비즈니스 로직 procedure 호출 시의 주요 파라미터
      - before/after <- 없어서 디버깅 시 한 번 고생했음. 메인 서버에는 있는데 추가해야겠다.

- 로그 남기는 전략

  - AOP 스러운 접근
  - Enhancer 스타일로 AOP를 구현하고 있음
    (예시 코드 ㄱㄱ)

- 부수효과
  - 사용자 행동 추적하는 효과가 있음
  - 활용 사례
    - KPI 추출
    - 기능 릴리즈 이후 활성도 점검

### 읽기 전용 데이터베이스와 쿼리 시각화 도구

- 일단 개발자가 직접 운영 DB에 접속해서 쿼리를 날리는 게 일반적인 습관으로 자리잡는 것은 아주 나쁜 생각임
  - https://techblog.woowahan.com/2645/ 를 읽어보길 바람
- 안전한 데이터 조회를 위해 read replica를 운용하고 있음

- 이것에 더해 쿼리 시각화 도구 (Redash) 를 사용하고 있음 -> 개발자들이 redash에서 쿼리를 날려보면서 개발과 디버깅을 하는 것이 일상적

  - 굳이 시각화 기능을 사용하지 않더라도 충분히 유용함
    - SAML을 연결할 수 있고
    - 자주 사용하는 쿼리를 저장해두거나
    - 데이터 export 기능을 편리하게 이용하고 있음

- 쿼리 시각화

  - SQL을 몰라서 직접 쿼리를 짤 수 없더라도 주요 지표를 확인할 수 있음
  - 서비스 초기부터 핵심 지표를 정해두고 Redash에 대시보드로 만들어둠 -> 매주 리포트를 공유 (리포트 쓰는데 15분밖에 안 걸림)

- 백오피스 툴 중에서 가장 팀에서 일상적으로 사용하고 있는 듯.

- 물론 (백엔드팀 Admin Cell과 웹 클라이언트 팀에서 개발한) "진짜" 백오피스도 있음
  - 아직 우리 팀에서 운영하는 기능과 연결이 안되어있음
  - 효과: CX팀에서 직접 고객 문의와 관련된 맥락을 파악 못하고 개발자에게 하나하나 문의해야 함 -> 하루에 30분 40분 씩 시간 쓰는 요인
  - 백오피스에서 우리가 관리하는 엔티티를 읽고 검색할 수 있으면 나는 하루에 30분씩 획득

### 백업

- 다행히 고객 데이터를 날려먹은 적은 없음
- 개발 환경에서 데이터베이스를 통쨰로 날려먹은 적은 있음 (개발자 업적 달성 축하드립니다. :tada:)
  - 스테이징 환경에 붙어서 통합테스트를 실행하며 데이터베이스 테이블이 truncate 된게 원인이었음
  - 한 번 경험한 다음에 재발 안하도록 방지해둠 (역시 맞아가며 배우는것)
- 당시에 복구는 Amazon RDS의 PITR 기능을 활용하여 할 수 있었음
  - PITR 로부터 새 인스턴스 실행 -> pg_dump -> 원래 데이터베이스에 부어주기
  - 스테이징 데이터베이스는 하루에 한 번 백업하기 때문에 12시간 어치 데이터를 날려먹긴 함..
  - 운영 환경에서는 위에 쓴 방법으로 복구 못할텐데
  - 장애 대응훈련이 필요하다

## Admin

- 토이프로젝트만 개발해본 뉴비에게 실제 서비스 운영 경험을 꼭 추천하는 이유
- 많은 서비스에서 코어 비즈니스 로직은 사실 그렇게 까다로운 부분은 아님
- 버그로부터 생긴 데이터 부정합 고치기, 고객 요청에 따른 데이터 확인 또는 수정, 신규 기능 추가에 따른 마이그레이션이 개발자의 시간을 잡아먹음
  - 특히 고객사 요청 **정말** 많음. 단순 확인 문의부터 데이터 옮겨주세요/부어주세요 등등
- 중요한 고객의 요청 하나를 해결하는데 내 3일을 쓰면 내 일을 할 시간이 없을것임
- 이 부분을 적은 노력으로 해결해야 내 시간을 절약해서 고객에게 필요한 기능을 개발하는 데 더 쓸 수 있음

### Admin API

- 모든 엔티티에 대한 읽기와 쓰기는 항상 만들어둔다.
- 내 일을 줄여줄 수 있도록 반복적으로 들어오는 요청을 해결하는 것들 위주로
- Admin API 호출도 호출 로그와 audit log가 남아야 함
- SDK
  - 서버사이드에서 Admin API를 만들었으면, 그걸 클라이언트 사이드에서 코드로 호출할 수 있는 SDK를 준비
  - 코드를 generate할 수 있는 도구도 많이 있음. (gRPC같은걸 쓴다면 특히) 이런 걸 아직 사용하고 있지는 않음
  - 셸스크립트도 있지만 셸코드보다 일반 프로그래밍 언어가 익숙하기 때문에..
  - 메인 프로젝트와 동일한 환경에서, 코드와 비즈니스 로직을 공유하며 Admin API를 활용하는 스크립트를 작성할 수 있게 됨 (메인 어플리케이션과 스크립트를 모노레포로 구성)

### 재사용 가능한 스크립트

- Admin API와 모노레포 구조를 통해 복잡한 로직을 담은 스크립트를 30분 내에 뚝 딱 할 수 있게 됨
  - 데이터 스캔하면서 통계값을 뽑거나, 데이터의 정합성 맞추는 스크립트
  - 외부 데이터를 import 혹은 export
  - Secondary database로의 전체 혹은 부분 데이터 동기화
- 로그
  - 스크립트에서 progress 로그를 print하지 않으면, 스크립트를 실행하는 순간 딜레마에 빠지게 됨
    - 돌고 있는건지 막혀있는건지 그냥 오래걸리는건지 공포에 떨어야 함
  - 로그에 정보를 되도록 많이 담아야 잘못 돌았을 때 실수를 커버할 수 있음
- Dry run 옵션
  - 운영환경 데이터에 개발환경과 다른 문제가 있을 수도 있음
  - 단순히 개발환경에서 충분히 많은 케이스를 테스트를 못했을 수도 있고
  - 업데이트를 여러 번 하면서 데이터 정합성이 변했다던가, 미처 마이그레이션 못한 옛날 데이터라던가, 등등
  - Dry run 옵션을 두고 충실하게 구현하면 안전하게 스크립트를 테스트 할 수 있음
- Documentation과 스크립트 실행 옵션에 대한 설명을 상세히 달아두면 내가 휴가 갔을 때도 돌릴 수 있는 스크립트가 됨 (맥북 두고 휴가 갈 수 있음)
- 부수효과
  - 내부 기능 테스트할 때 간결하게 환경을 세팅할 수 있게 됨
  - 특히 AI(RAG) 기능 (AI Agent가 답변하기 위한 knowledge base가 필요할 때.)

### 이제 고객 요청 별로 안 무서움

- 정리하면 여기에서 스노우볼이 굴렀다고 생각함
  - 반복적으로 쿼리하게 되는걸 Admin API를 만들어둠 -> Admin API가 있으니 복잡한 요청들을 거절하지 않고 API 요청 몇개로 쉽게 해결해줄 수 있게 됨
  - 다시 반복되는 패턴을 Admin SDK와 스크립트로 만들어둠
  - 스크립트가 많이 생기니 다시 패턴화가 되어 스크립트 템플릿도 만들고 나 말고 다른 사람들이 대신 작성하고 돌릴 수 있게 됨
- 이제는 Admin API나 SDK는 따로 고객 요청이 있었다고 느끼지 않아도 미리 만들어두게 됨
- 고객사 퀘스트 클리어 보상은 좋은 고객경험, 서비스에 대한 락인, 그리고 KPI 상승
- 귀찮음이나 무서움을 덜고 적극적으로 퀘스트를 깰 수 있음
  - 일주일에 복잡한 요청 2~3개 처리하면서 기능 개발 스케줄에도 문제가 없었음

## Reliability

- 6월 27일 릴리즈 이후 3번의 incident가 있었음
- 2개는 서비스 중단 (다 합해서 40분 정도.), 1개는 데이터 정합성 오류 및 내부 데이터 일부 손실
- 실수를 할 수는 있는데, 1) 실수 한 것을 최대한 빨리 인지하는 것 2) 고객에게 장애 발생을 전파하고 3) 이유와 복구 상황을 설명하는 것 4) 실수를 수습하는 과정이 좋은 고객 경험을 만듬
  - 40분이나 service outage된 것이 정말 아쉬움
  - 하나는 4분만에 고쳤는데 나머지 한 번 장애 때 팀에서 인지하는 데 30분 가량 걸림
  - 마지막 하나는 서비스가 겉으로 볼 때 정상적으로 돌아가는 것처럼 보이니 더 찾기 어려웠고, 하루 만에야 뭔가 잘못되었다는 것을 찾음
  - (당연하겠지만) 실수한 걸 빨리 찾을수록 수습이 쉬움
  - 1시간만에 찾았으면 데이터 몇 개 보정할 걸 하루만에 찾아서 몇백 개를 보정하느라 고생하게 됨
- 실수를 두려워해서 모든 코드를 리더가 리뷰하고, 새로운 기술 도입에 소극적이고, 기능 릴리즈를 늦게 하는 것이 아니라, 실수해도 빠르게 바로잡을 수 있는 환경을 만들자

### 알람

- ...

### 로그

- ...

## (아직은) 크게 도움이 안 되었던 것들

- Request Trace
  - HTTP req context에 trace id를 발급하고 이를 바탕으로 버그를 추적하려고 프로젝트 초기에 세팅
  - 아직 비즈니스 로직이 간단하고 execution path를 따라가기 어렵지 않음. 그래서 흩어져 있는 로그를 trace id와 함께 보는 경우가 없었음
- Datadog APM과 Trace
  - 같은 이유로 APM도 아직 도움은 안 됨
  - 사실 메인 API 서버에서는 아주 잘 쓰고 있음, 그런데 지금 하고 있는 작은 프로젝트에서는 sentry와 application log로도 충분
    - 메인 API 서버에서 아주 잘 쓰고있는 기능
      - 코드에서 critical section에 따로 trace 달아서 퍼포먼스 모니터링 (HTTP trace로 보이지 않는 queue나 stream을 consuming하는 부분에서 유용)
      - Service dependency map과 서비스별 체류 시간: 장애 발생 시 바로 보는 지표로, 어떤 컴포넌트가 문제인지 즉시 파악할 수 있게 해줌
      - 넓은 시간 범위의 (주~달 단위) 트렌드 파악: 시간이 지날수록 성능이 악화되어 개선이 필요한 기능을 짚어낼 수 있게 해줌 -> 3~4달 후에 잠재적인 장애 예방
  - 비싸긴 한데 돈값은 한다
  - 그런데 작은 프로젝트에서는 글쎄
  - 프로젝트가 더 커지면, 또는 성능 개선할 때 도움이 될 것 같다.
  - 겸사겸사 다른 마이크로서비스로의 요청이나, RDS 쿼리에 대한 trace를 달아두었다.
